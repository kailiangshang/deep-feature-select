# DeepFS - Deep Feature Selection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ä¸€ä¸ªçµæ´»ã€æ¨¡å—åŒ–çš„æ·±åº¦ç‰¹å¾é€‰æ‹©åº“ï¼Œå®ç°äº†å¤šç§æœ€å…ˆè¿›çš„å¯å¾®ç‰¹å¾é€‰æ‹©ç®—æ³•ã€‚

## ğŸŒŸ ç‰¹æ€§

- **ğŸ† æ ¸å¿ƒç®—æ³•**: IPCAE + åµŒå…¥å¼ Gumbel-Softmax é—¨æ§çš„ç»„åˆæ–¹æ³•ï¼Œå®ç°é«˜æ•ˆçš„ä¸¤é˜¶æ®µç‰¹å¾é€‰æ‹©
- **æ¨¡å—åŒ–è®¾è®¡**: é—¨æ§(Gate)ã€ç¼–ç å™¨(Encoder)ã€é€‰æ‹©å™¨(Selector)å¯è‡ªç”±ç»„åˆ
- **å¤šç§ç®—æ³•**: å®ç° 4 ç§é—¨æ§ç®—æ³• + 2 ç§ç¼–ç å™¨ç®—æ³• + 8 ç§ç»„åˆæ–¹æ³•
- **æ˜“äºæ‰©å±•**: æ¸…æ™°çš„åŸºç±»è®¾è®¡ï¼Œæ–¹ä¾¿å®ç°æ–°ç®—æ³•
- **ç”Ÿäº§å°±ç»ª**: å®Œæ•´çš„ç±»å‹æ³¨è§£ã€æ–‡æ¡£å­—ç¬¦ä¸²ã€å•å…ƒæµ‹è¯•

## ğŸ”¥ æ ¸å¿ƒç®—æ³•: GSG-IPCAE

æˆ‘ä»¬æå‡ºçš„æ ¸å¿ƒç®—æ³•æ˜¯ **åµŒå…¥å¼ Gumbel-Softmax é—¨æ§ (GSG) + é—´æ¥å‚æ•°åŒ–æ··å‡åœŸè‡ªç¼–ç å™¨ (IPCAE)** çš„ç»„åˆï¼Œå®ç°ä¸¤é˜¶æ®µç‰¹å¾é€‰æ‹©ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GSG-IPCAE ä¸¤é˜¶æ®µç‰¹å¾é€‰æ‹©æ¶æ„                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   è¾“å…¥ç‰¹å¾ X âˆˆ R^{NÃ—D}                                                      â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Stage 1: IPCAE (é—´æ¥å‚æ•°åŒ–æ··å‡åœŸç¼–ç å™¨)                              â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚   â”‚  ç‰¹å¾åµŒå…¥ E âˆˆ R^{DÃ—d}     é€‰æ‹©æ¦‚ç‡ Î± âˆˆ R^{DÃ—k_max}           â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  (ä½ç§©å‚æ•°åŒ–)              (Concrete Distribution)           â”‚   â”‚   â”‚
â”‚  â”‚   â”‚       â†“                          â†“                          â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  logits = E @ W          Gumbel-Softmax é‡‡æ ·                 â”‚   â”‚   â”‚
â”‚  â”‚   â”‚       â†“                          â†“                          â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  é€‰æ‹© k_max ä¸ªå€™é€‰ç‰¹å¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º X' âˆˆ R^{NÃ—k_max}   â”‚   â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Stage 2: GSG (åµŒå…¥å¼ Gumbel-Softmax é—¨æ§)                           â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚   â”‚  é—¨æ§åµŒå…¥ G âˆˆ R^{k_maxÃ—d'}   é—¨æ§æ¦‚ç‡ Ï€ âˆˆ R^{k_max}           â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  (ä½ç§©å‚æ•°åŒ–)                 (Gumbel-Sigmoid)               â”‚   â”‚   â”‚
â”‚  â”‚   â”‚       â†“                           â†“                         â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  gates = Ïƒ(G @ v + Îµ)     ç¨€ç–æ­£åˆ™åŒ– L0æƒ©ç½š                   â”‚   â”‚   â”‚
â”‚  â”‚   â”‚       â†“                           â†“                         â”‚   â”‚   â”‚
â”‚  â”‚   â”‚  ä» k_max å€™é€‰ä¸­ç­›é€‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º X'' âˆˆ R^{NÃ—k}          â”‚   â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚   è¾“å‡º: é€‰æ‹© k ä¸ªæœ€ä¼˜ç‰¹å¾ (k < k_max << D)                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸ºä»€ä¹ˆé€‰æ‹© GSG-IPCAE?

| ç‰¹æ€§ | ä¼ ç»Ÿæ–¹æ³• | GSG-IPCAE |
|-----|---------|-----------|
| **å‚æ•°é‡** | O(D) æˆ– O(DÂ²) | O(DÃ—d) ä½ç§©å‚æ•°åŒ– |
| **ç‰¹å¾æ•°é‡** | å›ºå®šæˆ–ä¸ç¨³å®š | ä¸¤é˜¶æ®µç²¾ç¡®æ§åˆ¶ |
| **ç¨€ç–æ€§** | éœ€è¦ L1 æ­£åˆ™ | å¤©ç„¶ç¨€ç– + L0 æ­£åˆ™ |
| **å¯å¾®æ€§** | éƒ¨åˆ†å¯å¾® | å®Œå…¨å¯å¾® |
| **ç‰¹å¾å…³è”** | ç‹¬ç«‹é€‰æ‹© | è€ƒè™‘ç‰¹å¾å…³è” |

### å¿«é€Ÿä½¿ç”¨ GSG-IPCAE

```python
import torch
from deepfs import GumbelSoftmaxGate, IndirectConcreteEncoder, GateEncoderSelector

# åˆ›å»º GSG-IPCAE é€‰æ‹©å™¨
encoder = IndirectConcreteEncoder(
    input_dim=58482,      # åŸå§‹ç‰¹å¾æ•° (å¦‚åŸºå› æ•°)
    output_dim=100,       # ç¬¬ä¸€é˜¶æ®µé€‰æ‹© k_max ä¸ªå€™é€‰
    embedding_dim=32,     # ä½ç§©åµŒå…¥ç»´åº¦ (èŠ‚çœå‚æ•°)
)

gate = GumbelSoftmaxGate(
    input_dim=100,        # ä» k_max ä¸ªå€™é€‰ä¸­ç­›é€‰
    embedding_dim=16,     # é—¨æ§åµŒå…¥ç»´åº¦
)

selector = GateEncoderSelector(gate, encoder)

# è®­ç»ƒ
x = torch.randn(32, 58482)  # 32 æ ·æœ¬, 58482 ç‰¹å¾
selected_x = selector(x)     # -> 32 æ ·æœ¬, ~50 ç‰¹å¾ (ç”± Î» æ§åˆ¶)

# è·å–ç¨€ç–æŸå¤±
sparsity_loss = gate.sparsity_loss().total
total_loss = task_loss + 0.1 * sparsity_loss
```

## ğŸ“¦ å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-repo/deep-feature-select.git
cd deep-feature-select

# å®‰è£…ä¾èµ– (ä½¿ç”¨ uv)
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -e .
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
import torch
from deepfs import StochasticGate, GumbelSigmoidGate, HardConcreteGate
from deepfs import ConcreteEncoder, IndirectConcreteEncoder
from deepfs import GateEncoderSelector

# 1. çº¯é—¨æ§æ–¹æ³• - ä½¿ç”¨ç¨€ç–æŸå¤±æ§åˆ¶ç‰¹å¾æ•°é‡
input_dim = 1000
gate = StochasticGate(input_dim=input_dim, sigma=0.5)

# è®­ç»ƒæ—¶
x = torch.randn(32, input_dim)  # batch_size=32
selected_x = gate(x)  # åº”ç”¨ç‰¹å¾é€‰æ‹©

# è·å–ç¨€ç–æŸå¤±
sparsity_loss = gate.sparsity_loss().total
total_loss = task_loss + 0.1 * sparsity_loss  # Î»=0.1 æ§åˆ¶ç¨€ç–ç¨‹åº¦

# 2. ç¼–ç å™¨æ–¹æ³• - ç›´æ¥é€‰æ‹© k ä¸ªç‰¹å¾
encoder = ConcreteEncoder(input_dim=1000, output_dim=50)  # é€‰æ‹© 50 ä¸ªç‰¹å¾
selected_x = encoder(x)

# 3. ç»„åˆæ–¹æ³• - ç¼–ç å™¨é€‰å€™é€‰ç‰¹å¾ï¼Œé—¨æ§è¿›ä¸€æ­¥ç­›é€‰
gate = GumbelSigmoidGate(input_dim=50)  # ä» 50 ä¸ªå€™é€‰ä¸­ç­›é€‰
selector = GateEncoderSelector(gate, encoder)
selected_x = selector(x)
```

### å®Œæ•´è®­ç»ƒç¤ºä¾‹

```python
import torch
import torch.nn as nn
from deepfs import StochasticGate

# å®šä¹‰å¸¦ç‰¹å¾é€‰æ‹©çš„æ¨¡å‹
class FeatureSelectionClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super().__init__()
        self.gate = StochasticGate(input_dim=input_dim, sigma=0.5)
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, num_classes)
        )
    
    def forward(self, x):
        x = self.gate(x)
        return self.classifier(x)
    
    def sparsity_loss(self):
        return self.gate.sparsity_loss().total

# è®­ç»ƒ
model = FeatureSelectionClassifier(input_dim=1000, hidden_dim=128, num_classes=5)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()
lambda_sparsity = 0.1

for epoch in range(100):
    for batch_x, batch_y in train_loader:
        optimizer.zero_grad()
        outputs = model(batch_x)
        
        # ä»»åŠ¡æŸå¤± + ç¨€ç–æŸå¤±
        loss = criterion(outputs, batch_y)
        loss = loss + lambda_sparsity * model.sparsity_loss()
        
        loss.backward()
        optimizer.step()

# æ¨ç†
model.eval()
with torch.no_grad():
    outputs = model(test_x)
    predictions = outputs.argmax(dim=1)
    
# è·å–é€‰æ‹©çš„ç‰¹å¾
num_selected = model.gate.num_selected
print(f"é€‰æ‹©äº† {num_selected} ä¸ªç‰¹å¾")
```

## ğŸ”§ ä½¿ç”¨è‡ªå·±çš„æ•°æ®

DeepFS æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼š

### æ–¹å¼1: PyTorch Tensor

```python
import torch
from torch.utils.data import DataLoader, TensorDataset

# å‡†å¤‡æ•°æ®
X = torch.randn(1000, 500)  # 1000 æ ·æœ¬, 500 ç‰¹å¾
y = torch.randint(0, 3, (1000,))  # 3 åˆ†ç±»ä»»åŠ¡

dataset = TensorDataset(X, y)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# è®­ç»ƒ
for batch_x, batch_y in train_loader:
    outputs = model(batch_x)
    loss = criterion(outputs, batch_y) + lambda_sparsity * model.sparsity_loss()
    # ...
```

### æ–¹å¼2: AnnData (å•ç»†èƒæ•°æ®)

```python
import scanpy as sc
from exp.data.dataset_all import generate_train_test_loader

# åŠ è½½ h5ad æ ¼å¼æ•°æ®
# æ•°æ®éœ€åŒ…å« 'cell_type' åˆ—ä½œä¸ºæ ‡ç­¾
metadata = generate_train_test_loader(
    name="pancreas",  # exp/data/pancreas.h5ad
    test_size=0.2,
    batch_size=32,
    device="cuda"
)

# ä½¿ç”¨æ•°æ®
for batch in metadata.train_loader:
    x = batch.X  # ç‰¹å¾
    y = batch.obs['cell_type']  # æ ‡ç­¾
    # ...
```

> ğŸš§ **æ›´å¤šæ•°æ®é›†å³å°†æ¨å‡º**: æˆ‘ä»¬æ­£åœ¨å‡†å¤‡æ›´å¤šå…¬å¼€æ•°æ®é›†çš„ä¸‹è½½é“¾æ¥å’Œä½¿ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬æ ‡å‡†ç‰¹å¾é€‰æ‹©åŸºå‡†æ•°æ®é›†ã€‚æ•¬è¯·æœŸå¾…ï¼

### æ–¹å¼3: NumPy æ•°ç»„

```python
import numpy as np
import torch

# ä»æ–‡ä»¶åŠ è½½
X = np.loadtxt("features.csv", delimiter=",")
y = np.loadtxt("labels.csv", delimiter=",")

# æˆ–ä»å…¶ä»–æ¥æº
# X = your_data_pipeline()
# y = your_labels()

# è½¬æ¢ä¸º PyTorch
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.long)
```

### æ–¹å¼4: Pandas DataFrame

```python
import pandas as pd
import torch

df = pd.read_csv("your_data.csv")
X = torch.tensor(df.drop(columns=["label"]).values, dtype=torch.float32)
y = torch.tensor(df["label"].values, dtype=torch.long)
```

## ğŸ“Š å®Œæ•´å®éªŒæµç¨‹

æˆ‘ä»¬æä¾›äº†å®Œæ•´çš„å®éªŒè„šæœ¬ï¼š

```bash
# è¿è¡Œæ‰€æœ‰å®éªŒ (å¯¹æ¯”å®éªŒ + æ¶ˆèå®éªŒ)
python exp/run_experiment.py

# æˆ–å•ç‹¬è¿è¡Œå¿«é€Ÿæµ‹è¯•
python exp/run_quick_test.py
```

å®éªŒç»“æœå°†ä¿å­˜åœ¨ `exp/results/` ç›®å½•ä¸‹ï¼š
- `contrast/gate_only.csv` - çº¯é—¨æ§å®éªŒç»“æœ
- `contrast/encoder_only.csv` - çº¯ç¼–ç å™¨å®éªŒç»“æœ  
- `contrast/gate_encoder.csv` - ç»„åˆæ–¹æ³•å®éªŒç»“æœ
- `ablation/ablation.csv` - æ¶ˆèå®éªŒç»“æœ

## ğŸ“š ç®—æ³•è¯´æ˜

### é—¨æ§æ–¹æ³• (Gate Methods)

| ç®—æ³• | æè¿° | è®ºæ–‡ |
|-----|------|------|
| **StochasticGate** | é«˜æ–¯å™ªå£°éšæœºé—¨æ§ | [STG, ICML 2020](http://proceedings.mlr.press/v119/yamada20a.html) |
| **GumbelSigmoidGate** | Gumbel-Sigmoid æ¾å¼›é—¨æ§ | [Gumbel-Softmax, 2016](https://arxiv.org/abs/1611.01144) |
| **GumbelSoftmaxGate** | åµŒå…¥å¼ Gumbel-Softmax é—¨æ§ | [Gumbel-Softmax, 2016](https://arxiv.org/abs/1611.01144) |
| **HardConcreteGate** | ç¡¬æ··å‡åœŸåˆ†å¸ƒé—¨æ§ | [L0 Regularization, ICLR 2018](https://openreview.net/forum?id=H1Y8hhg0b) |

**ç‰¹ç‚¹**: é€šè¿‡ç¨€ç–æŸå¤±æ§åˆ¶ç‰¹å¾æ•°é‡ï¼Œç‰¹å¾æ•°é‡ä¸å›ºå®š

### ç¼–ç å™¨æ–¹æ³• (Encoder Methods)

| ç®—æ³• | æè¿° | è®ºæ–‡ |
|-----|------|------|
| **ConcreteEncoder** | æ··å‡åœŸè‡ªç¼–ç å™¨ | [CAE, ICML 2019](https://proceedings.mlr.press/v97/balin19a.html) |
| **IndirectConcreteEncoder** | é—´æ¥å‚æ•°åŒ–æ··å‡åœŸç¼–ç å™¨ | åŸºäº [CAE](https://proceedings.mlr.press/v97/balin19a.html) æ”¹è¿› |

**ç‰¹ç‚¹**: ç›´æ¥é€‰æ‹©å›ºå®š k ä¸ªç‰¹å¾ï¼Œæ— éœ€ç¨€ç–æŸå¤±

### ç»„åˆæ–¹æ³•

ç¼–ç å™¨å…ˆé€‰æ‹© k_max ä¸ªå€™é€‰ç‰¹å¾ï¼Œé—¨æ§å†è¿›ä¸€æ­¥ç­›é€‰ï¼š

```python
# 8 ç§ç»„åˆ
StochasticGate + ConcreteEncoder
StochasticGate + IndirectConcreteEncoder
GumbelSigmoidGate + ConcreteEncoder
GumbelSigmoidGate + IndirectConcreteEncoder
GumbelSoftmaxGate + ConcreteEncoder
GumbelSoftmaxGate + IndirectConcreteEncoder
HardConcreteGate + ConcreteEncoder
HardConcreteGate + IndirectConcreteEncoder
```

## âš™ï¸ è¶…å‚æ•°è¯´æ˜

### é—¨æ§æ–¹æ³•

```python
StochasticGate(
    input_dim=1000,      # è¾“å…¥ç‰¹å¾æ•°
    sigma=0.5,           # é«˜æ–¯å™ªå£°æ ‡å‡†å·®
    hard_gate_type="hard_zero",  # æ¨ç†æ—¶ç¡¬é—¨æ§ç±»å‹
)

GumbelSigmoidGate(
    input_dim=1000,
    initial_temperature=10.0,   # åˆå§‹æ¸©åº¦
    final_temperature=0.01,     # æœ€ç»ˆæ¸©åº¦
    total_epochs=100,           # æ¸©åº¦é€€ç«æ€»è½®æ•°
)

GumbelSoftmaxGate(
    input_dim=1000,
    embedding_dim=16,     # åµŒå…¥ç»´åº¦ (å‚æ•°æ•ˆç‡)
    # ... æ¸©åº¦å‚æ•°åŒä¸Š
)

HardConcreteGate(
    input_dim=1000,
    min_max_scale=(-0.1, 1.1),  # æ‹‰ä¼¸å‚æ•° (gamma, zeta)
    temperature=0.5,             # æ··å‡åœŸåˆ†å¸ƒæ¸©åº¦
)
```

### ç¼–ç å™¨æ–¹æ³•

```python
ConcreteEncoder(
    input_dim=1000,       # è¾“å…¥ç‰¹å¾æ•°
    output_dim=50,        # é€‰æ‹©çš„ç‰¹å¾æ•° k
    initial_temperature=10.0,
    final_temperature=0.01,
    total_epochs=100,
)

IndirectConcreteEncoder(
    input_dim=1000,
    output_dim=50,
    embedding_dim=32,     # ä½ç§©åµŒå…¥ç»´åº¦ (å‚æ•°æ•ˆç‡)
    # ... æ¸©åº¦å‚æ•°åŒä¸Š
)
```

### ç¨€ç–æŸå¤±æƒé‡ Î»

- **å° Î» (0.001-0.01)**: é€‰æ‹©æ›´å¤šç‰¹å¾ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ
- **ä¸­ Î» (0.1-1)**: å¹³è¡¡ç¨€ç–æ€§å’Œæ€§èƒ½
- **å¤§ Î» (10-100)**: é€‰æ‹©æ›´å°‘ç‰¹å¾ï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ

å»ºè®®é€šè¿‡ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å€¼ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
deep-feature-select/
â”œâ”€â”€ deepfs/                    # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ core/                  # åŸºç¡€ç±»å‹å’ŒæŠ½è±¡ç±»
â”‚   â”‚   â”œâ”€â”€ types.py          # ç±»å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ base.py           # åŸºç±»
â”‚   â”‚   â””â”€â”€ registry.py       # æ³¨å†Œè¡¨
â”‚   â”œâ”€â”€ gates/                 # é—¨æ§æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ stochastic.py     # éšæœºé—¨æ§ (STG)
â”‚   â”‚   â”œâ”€â”€ gumbel_sigmoid.py # Gumbel-Sigmoid é—¨æ§
â”‚   â”‚   â”œâ”€â”€ gumbel_softmax.py # Gumbel-Softmax é—¨æ§
â”‚   â”‚   â””â”€â”€ hard_concrete.py  # ç¡¬æ··å‡åœŸé—¨æ§
â”‚   â”œâ”€â”€ encoders/              # ç¼–ç å™¨æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ concrete.py       # æ··å‡åœŸç¼–ç å™¨ (CAE)
â”‚   â”‚   â””â”€â”€ indirect_concrete.py # é—´æ¥æ··å‡åœŸç¼–ç å™¨
â”‚   â”œâ”€â”€ selectors/             # é€‰æ‹©å™¨æ¨¡å—
â”‚   â”‚   â””â”€â”€ composite.py      # ç»„åˆé€‰æ‹©å™¨
â”‚   â”œâ”€â”€ training/              # è®­ç»ƒå·¥å…·
â”‚   â”‚   â”œâ”€â”€ trainer.py        # è®­ç»ƒå™¨
â”‚   â”‚   â””â”€â”€ callbacks.py      # å›è°ƒå‡½æ•°
â”‚   â””â”€â”€ __init__.py           # å…¬å…± API
â”œâ”€â”€ exp/                       # å®éªŒä»£ç 
â”‚   â”œâ”€â”€ run_experiment.py     # å®Œæ•´å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ run_quick_test.py     # å¿«é€ŸéªŒè¯è„šæœ¬
â”‚   â”œâ”€â”€ data/                 # æ•°æ®åŠ è½½
â”‚   â””â”€â”€ results/              # å®éªŒç»“æœ
â”œâ”€â”€ EXPERIMENT_PLAN.md        # å®éªŒè®¡åˆ’
â”œâ”€â”€ README.md                 # æœ¬æ–‡æ¡£
â””â”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®
```

## ğŸ”¬ å®éªŒå¤ç°

è¯¦è§ [EXPERIMENT_PLAN.md](EXPERIMENT_PLAN.md)

### å®éªŒå†…å®¹

1. **å¯¹æ¯”å®éªŒ** (412 ç»„)
   - çº¯é—¨æ§: 4 ç®—æ³• Ã— 6 Î»å€¼ = 24 ç»„
   - çº¯ç¼–ç : 2 ç®—æ³• Ã— 50 kå€¼ = 100 ç»„
   - ç»„åˆ: 8 ç®—æ³• Ã— 6 k_max Ã— 6 Î» = 288 ç»„

2. **æ¶ˆèå®éªŒ** (22 ç»„)
   - k_max å½±å“: 6 ç»„
   - Î» å½±å“: 6 ç»„
   - åµŒå…¥ç»´åº¦å½±å“: 5 + 5 ç»„

### è¯„ä¼°æŒ‡æ ‡

- **ä»»åŠ¡æ€§èƒ½**: åˆ†ç±»å‡†ç¡®ç‡
- **ç¨€ç–æ€§**: 1 - (é€‰æ‹©ç‰¹å¾æ•° / æ€»ç‰¹å¾æ•°)
- **å‚æ•°é‡**: å¯è®­ç»ƒå‚æ•°æ€»æ•°
- **ç¨³å®šæ€§**: 5 æ¬¡è¿è¡Œçš„æ ‡å‡†å·®/å‡å€¼

## ğŸ“– å¼•ç”¨

> ğŸ“ **è®ºæ–‡å³å°†å‘å¸ƒ**: æœ¬é¡¹ç›®çš„å­¦æœ¯è®ºæ–‡æ­£åœ¨å‡†å¤‡ä¸­ï¼Œå³å°†åœ¨ arXiv ä¸Šå‘å¸ƒã€‚æ•¬è¯·æœŸå¾…ï¼

å¦‚æœè¿™ä¸ªåº“å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{deepfs2024,
  author = {Your Name},
  title = {DeepFS: A Modular Deep Feature Selection Library},
  year = {2024},
  url = {https://github.com/your-repo/deep-feature-select},
  note = {arXiv preprint coming soon}
}
```

ç›¸å…³è®ºæ–‡ï¼š

```bibtex
@inproceedings{yamada2020feature,
  title={Feature Selection Using Stochastic Gates},
  author={Yamada, Yutaro and d'Aspremont, Alexandre and Watanabe, Shinji and Koyama, Shinya and Matsuo, Yutaka},
  booktitle={ICML},
  year={2020}
}

@inproceedings{balin2019concrete,
  title={Concrete Autoencoders for Differentiable Feature Selection},
  author={Balin, Mustafa Furkan and Ozturkler, Berk and Can, Mustafa and Dengiz, Emre and Yoldemir, Aykut and Karaca, Abdullah and Ozturk, Murat and Erkmen, Burak and Erdogan, Alper and Gunduz, Huseyin and others},
  booktitle={ICML},
  year={2019}
}

@inproceedings{louizos2018learning,
  title={Learning Sparse Neural Networks through $L_0$ Regularization},
  author={Louizos, Christos and Welling, Max and Kingma, Diederik P},
  booktitle={ICLR},
  year={2018}
}
```

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶